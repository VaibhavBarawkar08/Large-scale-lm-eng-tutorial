{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8a5fce-dfea-4600-a60e-290cbfd9efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size, hidden_size =4, 8\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.z1 = None\n",
    "        self.w1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_size, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        print(z1)\n",
    "        self.z1 = z1.clone().detach()\n",
    "        z2 = self.w2(z1)\n",
    "        return z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47aa79f-c606-452e-8773-8035f1086b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 0.0G\n",
      "all model parameters: 72\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params / 1e9:.1f}G\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2c6131-3c95-439b-ba28-40dd0d5f8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "lr = 1e-0\n",
    "optimizer = SGD(fp32_model.parameters(), lr=lr)\n",
    "# print(lr)  #1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82a695d1-dba8-43eb-80bf-712b3f357c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0906, -0.0177,  0.3129,  0.1098, -0.2905, -0.1271, -0.1763,  0.1325],\n",
       "        [-0.1657,  0.0474,  0.2535, -0.0791, -0.0824,  0.0549,  0.1489,  0.2605],\n",
       "        [-0.2464, -0.2973,  0.1691,  0.1777, -0.0475, -0.3374, -0.1192, -0.3453],\n",
       "        [ 0.2817,  0.3462,  0.2579, -0.2603,  0.1440, -0.1558,  0.0590,  0.2681],\n",
       "        [ 0.0908, -0.1774,  0.1442,  0.2615, -0.0706, -0.0726,  0.1265,  0.2917],\n",
       "        [-0.1459, -0.1778, -0.2187, -0.1222,  0.0954, -0.1505, -0.2023,  0.0204],\n",
       "        [ 0.0171,  0.3026, -0.2561, -0.3250, -0.1028,  0.3338,  0.1469,  0.0285],\n",
       "        [ 0.1566, -0.3480, -0.1715,  0.2985,  0.1476, -0.3179,  0.1371,  0.1631]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9602758d-c346-480e-aef1-f2ba311e870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2247,  0.1487,  0.0881, -0.2991,  0.0971, -0.0459,  0.2221, -0.1868]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22649bc8-db08-49c6-83d4-44d85a979aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2388, -0.0356, -0.1086,  0.4998,  0.0016, -0.5134, -0.0702, -0.0403],\n",
      "        [-0.6645, -0.0950, -0.7363,  0.5179, -0.5337, -0.3007,  0.6192, -0.6999],\n",
      "        [-0.4698,  0.1093, -0.9383,  0.2190, -0.0976, -0.2578,  0.8914, -0.2335],\n",
      "        [-0.3563, -0.7386,  0.2531, -0.5503,  0.1289,  0.4823, -0.4234,  0.9617]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logits type = torch.float32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "#batch_size, hidden_size =4, 8\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.float, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp32_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d02965d-c80d-4889-8215-97cdacfbca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss type = torch.float32'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# craete dummy data (bsz=4)\n",
    "#y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\") #batch_size =4\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.float32, device=\"cuda\") #batch_size =4\n",
    "#y = torch.tensor([[1.9]], dtype=torch.float32, device=\"cuda\")\n",
    "#y = torch.tensor([[1.9], [0.5]], dtype=torch.float32, device=\"cuda\")\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae67a22d-da80-4ae1-9e21-a42fb1205b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25.1515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.2023],\n",
      "        [-0.1529],\n",
      "        [ 0.0065],\n",
      "        [-0.2864]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[1.9000],\n",
      "        [9.5000],\n",
      "        [0.9000],\n",
      "        [1.2000]], device='cuda:0')\n",
      "tensor(25.1515, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(L)\n",
    "print(z2)\n",
    "print(y)\n",
    "loss = torch.sum((z2-y)**2/batch_size)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aef694d-05a1-4e10-9161-bf8604f21e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[ 0.2247,  0.1487,  0.0881, -0.2991,  0.0971, -0.0459,  0.2221, -0.1868]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-3.7081, -0.8472, -3.8109,  2.4147, -2.4251, -1.7939,  3.2204, -2.9970]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L.backward()\n",
    "w2_weight = fp32_model.w2.weight.clone().detach()\n",
    "w1_weight = fp32_model.w1.weight.clone().detach()\n",
    "print(f'before: {fp32_model.w2.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w2.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781fba10-4815-4e48-a771-bcd19292e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0512],\n",
      "        [-4.8265],\n",
      "        [-0.4467],\n",
      "        [-0.7432]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([4, 8])\n",
      "tensor([[-0.2388, -0.0356, -0.1086,  0.4998,  0.0016, -0.5134, -0.0702, -0.0403],\n",
      "        [-0.6645, -0.0950, -0.7363,  0.5179, -0.5337, -0.3007,  0.6192, -0.6999],\n",
      "        [-0.4698,  0.1093, -0.9383,  0.2190, -0.0976, -0.2578,  0.8914, -0.2335],\n",
      "        [-0.3563, -0.7386,  0.2531, -0.5503,  0.1289,  0.4823, -0.4234,  0.9617]],\n",
      "       device='cuda:0')\n",
      "torch.Size([1, 8])\n",
      "tensor([[ 3.9328,  0.9959,  3.8990, -2.7137,  2.5223,  1.7479, -2.9982,  2.8101]],\n",
      "       device='cuda:0', grad_fn=<MmBackward0>)\n",
      "tensor([[ 0.2247,  0.1487,  0.0881, -0.2991,  0.0971, -0.0459,  0.2221, -0.1868]],\n",
      "       device='cuda:0')\n",
      "tensor([[-3.7081, -0.8472, -3.8109,  2.4147, -2.4251, -1.7939,  3.2204, -2.9970]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "DL_Dz2= 2 * (z2 - y) / batch_size # DL/Dz2  (BWD-activation: layer2), in case of MSE\n",
    "print(DL_Dz2) # [4,1] [output_size=1, batch_size] DL/Dz2\n",
    "Dz2_Dw2 = fp32_model.z1.clone().detach() #Dz2/Dw2\n",
    "print(Dz2_Dw2.shape) #[4,8] [batch_size, hidden_size] \n",
    "print(Dz2_Dw2)\n",
    "#DL_Dw2 = DL_Dz2.T * Dz2_Dw2\n",
    "DL_Dw2 = torch.matmul(DL_Dz2.T, Dz2_Dw2) #[1,4] * [4,8] batch_size, hidden_size\n",
    "print(DL_Dw2.shape) # [1,8] [output_size=1, hidden_size]\n",
    "print(DL_Dw2)\n",
    "print(w2_weight) # [hidden_size=8 , output_size=1]\n",
    "print(w2_weight - lr * DL_Dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2dbab75-ab40-44ef-a2eb-3a73f57026ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7844,  0.9291,  0.5532, -0.3136,  1.4755,  1.2774,  0.0164, -0.5525],\n",
       "        [ 0.4135,  0.6742,  0.4127, -0.3594,  1.0867,  0.9848,  0.2765, -0.1931],\n",
       "        [ 0.0969,  0.0742,  0.2634,  0.0116,  0.6454,  0.2137, -0.0436, -0.6141],\n",
       "        [-0.8831, -0.9141, -0.0621,  0.3033, -2.2068, -2.0254, -0.1976,  1.1800],\n",
       "        [ 0.4692,  0.2320,  0.2481,  0.0785,  0.6930,  0.5347,  0.2098, -0.0045],\n",
       "        [-0.3247, -0.3713, -0.2678, -0.0357, -0.2654, -0.4375, -0.2416,  0.1604],\n",
       "        [ 0.8823,  1.2388, -0.0184, -0.7437,  1.6433,  1.7225,  0.3375, -0.6488],\n",
       "        [-0.5712, -1.1355, -0.3714,  0.6507, -1.3211, -1.4860, -0.0232,  0.7329]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_model.w1.weight # w1 = [hidden_size, hidden_size] [8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0166765e-a2a7-456b-89a9-5c3accbc5658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0512],\n",
      "        [-4.8265],\n",
      "        [-0.4467],\n",
      "        [-0.7432]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "torch.Size([1, 8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([8, 8])\n",
      "tensor([[ 0.7844,  0.9291,  0.5532, -0.3136,  1.4755,  1.2774,  0.0164, -0.5525],\n",
      "        [ 0.4135,  0.6742,  0.4127, -0.3594,  1.0867,  0.9848,  0.2765, -0.1931],\n",
      "        [ 0.0969,  0.0742,  0.2634,  0.0116,  0.6454,  0.2137, -0.0436, -0.6141],\n",
      "        [-0.8831, -0.9141, -0.0621,  0.3033, -2.2068, -2.0254, -0.1976,  1.1800],\n",
      "        [ 0.4692,  0.2320,  0.2481,  0.0785,  0.6930,  0.5347,  0.2098, -0.0045],\n",
      "        [-0.3247, -0.3713, -0.2678, -0.0357, -0.2654, -0.4375, -0.2416,  0.1604],\n",
      "        [ 0.8823,  1.2388, -0.0184, -0.7437,  1.6433,  1.7225,  0.3375, -0.6488],\n",
      "        [-0.5712, -1.1355, -0.3714,  0.6507, -1.3211, -1.4860, -0.0232,  0.7329]],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "DL_Dz2= 2 * (z2 - y) / batch_size # DL/Dz2  (BWD-activation: layer2), in case of MSE\n",
    "print(DL_Dz2) # [4,1] [batch_size=4, output_size=1]\n",
    "print(w2_weight.shape) # [1,8]\n",
    "temp = torch.matmul(DL_Dz2, w2_weight) #DL/Dz2 * w2\n",
    "print(temp.shape) # [4,8]\n",
    "print(x.shape) # [4,8]\n",
    "DL_Dw1 = torch.matmul(temp.T, x) # [8,4] * [4,8] = [8,8]\n",
    "print(DL_Dw1.shape) #[8,8]\n",
    "print(w1_weight - lr * DL_Dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20942146-5f0b-4c2c-b02a-5c0e9255a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(512, 512, bias=False)\n",
    "        self.w2 = nn.Linear(512, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        z2 = self.w2(z1)\n",
    "        return z2\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "optimizer = SGD(fp32_model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f77d7-ecc4-461b-b36f-81139c9eb1b5",
   "metadata": {},
   "source": [
    "### Float2Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a79d4a4a-92ec-4cbc-9378-36f18a8d0c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp16_model = Net().half().to(\"cuda\")\n",
    "fp16_model.load_state_dict(fp32_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ffd276-1902-46c2-86de-83abd542298b",
   "metadata": {},
   "source": [
    "### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3877d42-2c6d-44d6-9df1-1f6778f2758f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logits type = torch.float16'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "batch_size, hidden_size = 4, 512\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.half, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp16_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afdde465-eb37-4d50-87ec-b561e8c21f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss type = torch.float16'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# craete dummy data (bsz=4)\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\")\n",
    "\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8bbdd-8569-41d0-87cc-93f842e88377",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dfa9df7-48b2-419c-85c5-73256959455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss scaling\n",
    "L *= 1024\n",
    "\n",
    "# do backward\n",
    "L.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3d467-45c6-4d1d-864b-f34cb185fe10",
   "metadata": {},
   "source": [
    "### Update Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e749deb2-6b96-4595-b3f1-c3d05e6d147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[-0.0225, -0.0107,  0.0302,  ...,  0.0010, -0.0359,  0.0066],\n",
      "        [ 0.0334, -0.0346,  0.0312,  ...,  0.0212, -0.0374,  0.0067],\n",
      "        [ 0.0124, -0.0137,  0.0121,  ..., -0.0433,  0.0172,  0.0341],\n",
      "        ...,\n",
      "        [-0.0394,  0.0279,  0.0392,  ...,  0.0374, -0.0026,  0.0150],\n",
      "        [-0.0053, -0.0111,  0.0289,  ...,  0.0046, -0.0286, -0.0411],\n",
      "        [-0.0161, -0.0105,  0.0411,  ..., -0.0264, -0.0139,  0.0388]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[-0.0225, -0.0107,  0.0302,  ...,  0.0010, -0.0359,  0.0066],\n",
      "        [ 0.0334, -0.0346,  0.0312,  ...,  0.0212, -0.0374,  0.0067],\n",
      "        [ 0.0124, -0.0137,  0.0121,  ..., -0.0433,  0.0172,  0.0341],\n",
      "        ...,\n",
      "        [-0.0394,  0.0279,  0.0392,  ...,  0.0374, -0.0026,  0.0150],\n",
      "        [-0.0053, -0.0111,  0.0289,  ...,  0.0046, -0.0286, -0.0411],\n",
      "        [-0.0161, -0.0105,  0.0411,  ..., -0.0264, -0.0139,  0.0388]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65aa4065-1520-444a-b6c3-99c1b57b9711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'before: {fp16_model.w1.weight}\\n')\n",
    "#optimizer.step()\n",
    "#print(f'after: {fp16_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "559310f0-09bc-4636-923d-9502f1f17f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy gradient to FP32 model\n",
    "fp32_model.w1.weight.grad = fp16_model.w1.weight.grad.float()\n",
    "fp32_model.w2.weight.grad = fp16_model.w2.weight.grad.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b6ac53-8d55-4732-b125-0b588078c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Parameter containing:\n",
      "tensor([[-0.0225, -0.0107,  0.0302,  ...,  0.0010, -0.0359,  0.0066],\n",
      "        [ 0.0334, -0.0346,  0.0312,  ...,  0.0212, -0.0374,  0.0067],\n",
      "        [ 0.0124, -0.0137,  0.0121,  ..., -0.0433,  0.0172,  0.0341],\n",
      "        ...,\n",
      "        [-0.0394,  0.0279,  0.0392,  ...,  0.0374, -0.0026,  0.0150],\n",
      "        [-0.0053, -0.0111,  0.0289,  ...,  0.0046, -0.0286, -0.0411],\n",
      "        [-0.0161, -0.0105,  0.0411,  ..., -0.0264, -0.0139,  0.0388]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[ 2.3910e-01, -6.1224e-01,  2.6777e+00,  ..., -4.3640e+00,\n",
      "          2.8267e-01, -3.1759e+00],\n",
      "        [-1.7368e-01,  4.4223e-01, -2.0663e+00,  ...,  3.4812e+00,\n",
      "         -2.8971e-01,  2.5280e+00],\n",
      "        [-3.0838e-02,  8.5775e-02, -4.2572e-01,  ...,  6.7855e-01,\n",
      "         -3.5368e-02,  5.6004e-01],\n",
      "        ...,\n",
      "        [ 1.8024e-01, -4.7868e-01,  2.2667e+00,  ..., -3.6351e+00,\n",
      "          2.6525e-01, -2.6625e+00],\n",
      "        [-4.2536e-04, -2.2271e-02,  7.8066e-02,  ..., -7.6418e-02,\n",
      "         -2.2728e-02, -1.0012e-01],\n",
      "        [ 9.9661e-03, -7.0561e-02,  3.0531e-01,  ..., -4.6205e-01,\n",
      "          1.7878e-02, -2.7873e-01]], device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ac8890c-f6a8-4a06-958d-25eb613a593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp32 grad: None\n",
      "\n",
      "before: Parameter containing:\n",
      "tensor([[ 0.0092, -0.0172, -0.0067,  ..., -0.0027,  0.0084, -0.0214],\n",
      "        [ 0.0358,  0.0061,  0.0276,  ...,  0.0274, -0.0038,  0.0103],\n",
      "        [-0.0320, -0.0291, -0.0293,  ...,  0.0085, -0.0079,  0.0432],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0156,  0.0021,  ...,  0.0162, -0.0098,  0.0191],\n",
      "        [ 0.0356, -0.0112, -0.0425,  ..., -0.0339, -0.0367,  0.0429],\n",
      "        [-0.0105,  0.0071,  0.0083,  ...,  0.0219, -0.0387,  0.0187]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[ 0.0092, -0.0172, -0.0067,  ..., -0.0027,  0.0084, -0.0214],\n",
      "        [ 0.0358,  0.0061,  0.0276,  ...,  0.0274, -0.0038,  0.0103],\n",
      "        [-0.0320, -0.0291, -0.0293,  ...,  0.0085, -0.0079,  0.0432],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0156,  0.0021,  ...,  0.0162, -0.0098,  0.0191],\n",
      "        [ 0.0356, -0.0112, -0.0425,  ..., -0.0339, -0.0367,  0.0429],\n",
      "        [-0.0105,  0.0071,  0.0083,  ...,  0.0219, -0.0387,  0.0187]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "fp32 grad: None\n",
      "\n",
      "f16 grad: tensor([[ 1.0468e-02,  1.9287e-02, -1.2238e-02,  ..., -1.6876e-02,\n",
      "         -2.0508e-02,  1.6953e-02],\n",
      "        [-4.8126e-02, -8.8684e-02,  5.6244e-02,  ...,  7.7576e-02,\n",
      "          9.4238e-02, -7.7942e-02],\n",
      "        [ 9.3689e-02,  1.7273e-01, -1.0956e-01,  ..., -1.5112e-01,\n",
      "         -1.8359e-01,  1.5186e-01],\n",
      "        ...,\n",
      "        [ 8.6670e-02,  1.5979e-01, -1.0132e-01,  ..., -1.3977e-01,\n",
      "         -1.6992e-01,  1.4038e-01],\n",
      "        [-7.4804e-05, -1.3781e-04,  8.7380e-05,  ...,  1.2058e-04,\n",
      "          1.4651e-04, -1.2112e-04],\n",
      "        [-8.4839e-02, -1.5625e-01,  9.9121e-02,  ...,  1.3672e-01,\n",
      "          1.6614e-01, -1.3745e-01]], device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "before: Parameter containing:\n",
      "tensor([[ 0.0092, -0.0172, -0.0067,  ..., -0.0027,  0.0084, -0.0214],\n",
      "        [ 0.0358,  0.0061,  0.0276,  ...,  0.0274, -0.0038,  0.0103],\n",
      "        [-0.0320, -0.0291, -0.0293,  ...,  0.0085, -0.0079,  0.0432],\n",
      "        ...,\n",
      "        [ 0.0158, -0.0156,  0.0021,  ...,  0.0162, -0.0098,  0.0191],\n",
      "        [ 0.0356, -0.0112, -0.0425,  ..., -0.0339, -0.0367,  0.0429],\n",
      "        [-0.0105,  0.0071,  0.0083,  ...,  0.0219, -0.0387,  0.0187]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "after: Parameter containing:\n",
      "tensor([[ 0.0091, -0.0174, -0.0066,  ..., -0.0026,  0.0087, -0.0216],\n",
      "        [ 0.0362,  0.0070,  0.0271,  ...,  0.0266, -0.0048,  0.0111],\n",
      "        [-0.0329, -0.0308, -0.0282,  ...,  0.0101, -0.0061,  0.0417],\n",
      "        ...,\n",
      "        [ 0.0149, -0.0172,  0.0032,  ...,  0.0176, -0.0081,  0.0177],\n",
      "        [ 0.0356, -0.0112, -0.0425,  ..., -0.0339, -0.0367,  0.0429],\n",
      "        [-0.0097,  0.0087,  0.0073,  ...,  0.0205, -0.0404,  0.0200]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint(f'before: {fp16_model.w1.weight}\\n')\\nprint(fp16_model.w1.weight.grad)\\noptimizer.step()\\nprint(fp16_model.w1.weight.grad)\\nprint(f'after: {fp16_model.w1.weight}\\n')\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(512, 512, bias=False)\n",
    "        self.w2 = nn.Linear(512, 1, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.w1(x)\n",
    "        z2 = self.w2(z1)\n",
    "        return z2\n",
    "\n",
    "from torch.optim import SGD\n",
    "\n",
    "fp32_model= Net().to(\"cuda\")\n",
    "optimizer = SGD(fp32_model.parameters(), lr=1e-2)\n",
    "#optimizer = SGD(fp32_model.parameters(), lr=1e-0)\n",
    "\n",
    "### Float2Half\n",
    "fp16_model = Net().half().to(\"cuda\")\n",
    "fp16_model.load_state_dict(fp32_model.state_dict())\n",
    "\n",
    "### Forward\n",
    "import torch\n",
    "\n",
    "# example input sizes\n",
    "batch_size, hidden_size = 4, 512\n",
    "\n",
    "# create dummy data (bsz=4, hid=256)\n",
    "x = torch.randn(batch_size,hidden_size, dtype=torch.half, device=\"cuda\") \n",
    "\n",
    "# do forward\n",
    "z2 = fp16_model(x)\n",
    "\n",
    "# check dtypr of output logits\n",
    "f\"logits type = {z2.dtype}\"\n",
    "\n",
    "\n",
    "# craete dummy data (bsz=4)\n",
    "y = torch.tensor([[1.9], [9.5], [0.9], [1.2]], dtype=torch.half, device=\"cuda\")\n",
    "\n",
    "# compute mean square error loss\n",
    "L = torch.nn.functional.mse_loss(z2, y)\n",
    "\n",
    "# check dtype of loss\n",
    "f\"loss type = {L.dtype}\"\n",
    "\n",
    "### Backward\n",
    "# loss scaling\n",
    "#L *= 1024\n",
    "\n",
    "# do backward\n",
    "L.backward()\n",
    "\n",
    "print(f'fp32 grad: {fp32_model.w1.weight.grad}\\n')\n",
    "### Update Weight\n",
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')\n",
    "print(f'fp32 grad: {fp32_model.w1.weight.grad}\\n')\n",
    "\n",
    "\n",
    "print(f'f16 grad: {fp16_model.w1.weight.grad}\\n')\n",
    "\n",
    "# copy gradient to FP32 model\n",
    "fp32_model.w1.weight.grad = fp16_model.w1.weight.grad.float()\n",
    "fp32_model.w2.weight.grad = fp16_model.w2.weight.grad.float()\n",
    "\n",
    "print(f'before: {fp32_model.w1.weight}\\n')\n",
    "optimizer.step()\n",
    "print(f'after: {fp32_model.w1.weight}\\n')\n",
    "\n",
    "\"\"\"\n",
    "print(f'before: {fp16_model.w1.weight}\\n')\n",
    "print(fp16_model.w1.weight.grad)\n",
    "optimizer.step()\n",
    "print(fp16_model.w1.weight.grad)\n",
    "print(f'after: {fp16_model.w1.weight}\\n')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171476-fd05-413e-914a-fa20b2d81e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "large-scale-lm",
   "language": "python",
   "name": "large-scale-lm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
